# LLM Settings (DeepSeek)
DEEPSEEK_KEY=
DEEPSEEK_BASE_URL=https://api.deepseek.com
DEEPSEEK_CHAT_MODEL=deepseek-chat
DEEPSEEK_REASONER_MODEL=deepseek-reasoner
LLM_TEMPERATURE=0.5

# Embedding Settings (OpenAI)
OPENAI_API_KEY=
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536
MAX_CHUNK_TOKENS=2000

# Vector Store (Qdrant)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
COLLECTION_NAME=codebase_chunks

# Reranking
CROSS_ENCODER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# Retrieval Boosting
SAME_FOLDER_BOOST=1.5
SAME_FILE_BOOST=2.0
TEST_PENALTY=0.01

# Processing Settings
MAX_CONCURRENT_TASKS=20
MAX_RETRIES=1
RETRIEVE_TIMEOUT=10
REVIEW_TIMEOUT=60
MAX_PLAN_RETRIES=2
SCC_MAX_RETRIES=3

# Generation Settings
USE_REASONER=true
ENABLE_LOGGING=true
PARALLEL_EXECUTION=true

# RAG Integration (requires Qdrant + OpenAI)
ENABLE_RAG=false
RAG_TOP_K=5
RAG_REINDEX=true
RAG_QUERY_STRATEGY=code_preview  # code_preview | dependencies | docstring_first

# Adaptive RAG (NEW - RAG-only retrieval with tool calling)
ENABLE_ADAPTIVE_RAG=false
MAX_TOOL_ROUNDS=3
AUTO_EXPAND_ON_REVIEW_FAIL=true
INITIAL_TOP_K=3

# Output
OUTPUT_DIR=./output
